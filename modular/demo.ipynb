{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.modular.com/engine/python/get-started.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python API for the Modular Inference Engine makes it easy to instantly upgrade your model’s inference performance. With just a few lines of code, you can run any TensorFlow or PyTorch model with reduced latency and compute cost.\n",
    "\n",
    "This page shows you how to load a trained TensorFlow model and execute it with the Modular Inference Engine. (It’s just as easy with a PyTorch model.) If you’d like to see performance benchmarks with other models, see our performance dashboard.\n",
    "\n",
    "We also offer a C API and our C++ API is coming soon.\n",
    "\n",
    "Import Python modules\n",
    "\n",
    "Nothing surprising here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from modular import engine\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load The Model\n",
    "\n",
    "First we need to create an InferenceSession and load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = engine.InferenceSession()\n",
    "model_path = Path('resnet50_v1_savedmodel')\n",
    "model = session.load(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This compiles the model into the Modular format for inference.\n",
    "\n",
    "Run an inference\n",
    "\n",
    "Before running the model, let’s check the input tensor shape and data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tensor in model.input_metadata:\n",
    "    print(f'shape: {tensor.shape}, dtype: {tensor.dtype}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension is None, meaning the batch size is dynamic.\n",
    "\n",
    "Just to demonstrate our API, let’s run an inference with random data that matches the input shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = np.random.rand(1, 224, 224, 3).astype(np.float32)\n",
    "\n",
    "model.execute(input_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s it! execute() returns the output as an ndarray.\n",
    "\n",
    "We can also run 5 inferences at once by batching them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_batch = np.repeat(input_tensor, 5, axis=0)\n",
    "\n",
    "model.execute(input_tensor_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s the same result five times, but this is just to show how easy it is to use the Python API with a TensorFlow or PyTorch model. This also does not illustrate the Inference Engine performance—for real benchmark examples, see our performance dashboard.\n",
    "\n",
    "For more details, check out the Python API reference.\n",
    "\n",
    "The Inference Engine is not publicly available yet, but if you’d like to get early access, please sign up here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketchbook-Uymnf8Ig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
